{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a3fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#  Load all necessary libraries  #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d5db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#   Import the Network Details   #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "# Define the Directory where the 4G Movil_Provision_Amdocs V4.xlsx file is located\n",
    "os.chdir(\"C://Users//Erica//Documents//Claro Peru//1. Layers\")\n",
    "# Import the excel file into a DatraFrame\n",
    "claro_detail_file = '4G Movil_Provision_Amdocs V4.xlsx'\n",
    "claro_net_detail = pd.read_excel(claro_detail_file)\n",
    "\n",
    "# Keep only the necessary columns\n",
    "claro_net_detail = claro_net_detail[['zone', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO', 'SUB_REGION', 'CLUSTER PROYECTO', 'MBTS_NAME', 'ENODEBFUNCTIONNAME']]\n",
    "\n",
    "# Remove duplicates as the parser only needs one row per eNodeB\n",
    "claro_net_detail = claro_net_detail.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Rename few columns to make it easier for the merge\n",
    "claro_net_detail.rename(columns={'zone':'ZONE','ENODEBFUNCTIONNAME':'eNodeB Name','CLUSTER PROYECTO':'CLUSTER'}, inplace=True)\n",
    "\n",
    "#Import the MAE\n",
    "Huawei_MAE_file = 'ZONE CLUSTER VS MAE LIMA AND PROVINCES.xlsx'\n",
    "Huawei_MAE = pd.read_excel(Huawei_MAE_file)\n",
    "\n",
    "# Keep only the necessary columns\n",
    "Huawei_MAE = Huawei_MAE[['Cluster', 'MAE']]\n",
    "\n",
    "# Remove duplicates as the parser only needs one row per eNodeB\n",
    "Huawei_MAE = Huawei_MAE.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Rename few columns to make it easier for the merge\n",
    "Huawei_MAE.rename(columns={'Cluster':'CLUSTER'}, inplace=True)\n",
    "\n",
    "#Merging both DataFrames\n",
    "# Capital Letter all Cluster Names \n",
    "claro_net_detail['CLUSTER'] = claro_net_detail['CLUSTER'].str.upper()\n",
    "Huawei_MAE['CLUSTER'] = Huawei_MAE['CLUSTER'].str.upper()\n",
    "\n",
    "claro_net_detail = pd.merge(claro_net_detail, Huawei_MAE, on=['CLUSTER'])\n",
    "\n",
    "#List the columns that will be merged with the MO Files\n",
    "colList = ['MAE','ZONE', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO', 'SUB_REGION', 'CLUSTER', 'MBTS_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7039012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#   Import Huawei MO/Parameter/  #\n",
    "#     subparameter dictionary    #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "# Load the Huawei MO/Parameter/Subparameter dictionary\n",
    "SubParameterList = pd.read_excel('SubparameterList.xlsx')\n",
    "\n",
    "# Create a MO Column with all letter in Capital letter\n",
    "SubParameterList['MOID'] = SubParameterList['MO'].str.upper()\n",
    "\n",
    "# Remove spaces between the Subparameters\n",
    "SubParameterList['Subparameter'] = SubParameterList['Subparameter'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c3e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-16 14:07:37.404970\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#   Loading all Configuration    #\n",
    "#    files exported from MAE     #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "# Define the Directory where the excel files are located\n",
    "##os.chdir(\"C://Users//Erica//Documents//Claro Peru//VoLTE//RLF Audit//exportMOs\")\n",
    "os.chdir(\"C://Users//Erica//Documents//Claro Peru//CA//Exports\")\n",
    "\n",
    "# Define the excel file extention to be used in the search\n",
    "extension = 'xlsx'\n",
    "\n",
    "# Add all excel files in the directory to a list. \n",
    "# Will only add the excel files that follows the template defined in the glob below \n",
    "all_filenames = [i for i in glob.glob('*BTS*.{}'.format(extension))]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79101d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\Erica\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-16 14:07:49.552498\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#   Loading MOs to DataFrames    #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "# List all sheet that you want import\n",
    "# sheet_to_include = ['ENODEBALGOSWITCH','GLOBALPROCSWITCH','ENODEBCONNSTATETIMER','CELLALGOSWITCH','CELLQCIPARA','CELLHOPARACFG','CELLULSCHALGO','CELLDLSCHALGO','VOLTEALGOCONFIG','CELLCQIADJALGO','CELLPDCCHALGO','ENBCELLRSVDPARA','RLCPDCPPARAGROUP','RLFTIMERCONSTGROUP','TIMEALIGNMENTTIMER','SRBRLCPDCPCFG','CELLBFMIMOPARACFG','INTERFREQHOGROUP','UECOMPATRSVDPARA','CELLTTIBUNDLINGALGO','CELLOP','VOICEAMRCONTROL','CELLRACTHD','CELLULCOMPALGO','EUTRANINTERNFREQ','INTRARATHOCOMM','QCIPARA','CELLPCALGO','PARAAUTOOPTCFG','ULCSALGOPARA','CELLPUCCHALGO','PUCCHCFG','CAMGTCFG','RACHCFG','UECOOPERATIONPARA','CELLMLB']\n",
    "# sheet_to_include = ['CELLQCIPARA','RRCCONNSTATETIMER','UETIMERCONST','RLFTIMERCONSTGROUP']\n",
    "sheet_to_include = ['PCCFREQCFG','SCCFREQCFG']\n",
    "\n",
    "# Loop thru all the excel files and load each sheet in a DF with the sheetName + df in front of it\n",
    "for f in all_filenames:\n",
    "    temp = pd.ExcelFile(f)\n",
    "    sheets = [sh for sh in temp.sheet_names if sh in sheet_to_include]\n",
    "    for s in sheets:\n",
    "        try:\n",
    "            if vars()['df'+ s] is not None:\n",
    "                df_temp = pd.read_excel(temp, sheet_name=s, skiprows=1)\n",
    "                vars()['df'+ s] = pd.concat([vars()['df'+ s], df_temp], ignore_index=True, sort=False)\n",
    "        except KeyError:\n",
    "            vars()['df'+ s] = pd.read_excel(temp, sheet_name=s, skiprows=1)\n",
    "df_temp = None\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f968e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#         Drop Parameters        #\n",
    "#           Not Listed           #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "#SubParameterList = SubParameterList[(SubParameterList['MOID'] == 'CELL') & ((SubParameterList['Parameter Name'] == '*Local Cell ID') | (SubParameterList['Parameter Name'] == '*Cell Name') | (SubParameterList['Parameter Name'] == '*Cell ID') | (SubParameterList['Parameter Name'] == '*Physical cell ID'))]\n",
    "\n",
    "#loop thru and drop Paramaters Columns for each MOs\n",
    "#for frame in sheet_to_include:\n",
    "#    param_keep = SubParameterList[SubParameterList['MOID']=='CELL']['Parameter Name'].tolist()\n",
    "#    try:\n",
    "#        vars()['df'+ frame].drop(columns=[col for col in vars()['df'+ frame] if col not in param_keep], inplace=True)\n",
    "#    except KeyError:\n",
    "#        print(\"The MO \"+ frame + \" doesn't exist!\")\n",
    "#        sheet_to_include = sheet_to_include.remove(frame)\n",
    "#        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6956934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Column Names by the ParameterID instead of the ParameterName\n",
    "\n",
    "#loop thru and put each on a specific sheet (sheetname is the DF Name without the initial df)\n",
    "for frame in sheet_to_include:\n",
    "    df_col_new_name = SubParameterList[SubParameterList['MOID']==frame][['Parameter ID', 'Parameter Name']]\n",
    "    dict_col_new_name = pd.Series(df_col_new_name['Parameter ID'].values, index=df_col_new_name['Parameter Name']).to_dict()\n",
    "    # First remove the brackets \"()\" and the \"*\" from the column names where it exists\n",
    "    try:\n",
    "        vars()['df'+ frame].columns = vars()['df'+ frame].columns.str.replace(r\"\\(.*\\)\",\"\", regex=True).to_list()\n",
    "        vars()['df'+ frame].columns = vars()['df'+ frame].columns.str.replace('*','').to_list()\n",
    "        # Then replace by the ParameterID\n",
    "        vars()['df'+ frame].rename(columns=dict_col_new_name, inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"The MO \"+ frame + \" doesn't exist!\")\n",
    "        sheet_to_include = sheet_to_include.remove(frame)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c548ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#  If MO is CELLQCIPARA, only    #\n",
    "#     select QCI1,5,6,7,8,9      #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "try: \n",
    "    dfCELLQCIPARA.drop(dfCELLQCIPARA[(dfCELLQCIPARA['Qci']!=1) & (dfCELLQCIPARA['Qci']!=5) & \\\n",
    "                                     (dfCELLQCIPARA['Qci']!=6) & (dfCELLQCIPARA['Qci']!=7) & \\\n",
    "                                     (dfCELLQCIPARA['Qci']!=8) & (dfCELLQCIPARA['Qci']!=9)].index, inplace=True)\n",
    "    dfCELLQCIPARA.reset_index(drop=True, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99da5bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-16 14:07:49.619082\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#  Expanding all Subparameters   #\n",
    "#     Into its own column        #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "# Split the Subparameters into new columns\n",
    "# Get the list of parameters:subparameters for the MO\n",
    "for frame in sheet_to_include:\n",
    "    df_subparameters = SubParameterList[(SubParameterList['MOID']==frame) & \\\n",
    "                                        (SubParameterList['Value Type'] == 'Bit Field Type')][['Parameter ID','Subparameter']]\n",
    "    df_subparameters.reset_index(drop=True)\n",
    "    for rows in df_subparameters.iterrows():\n",
    "        try: \n",
    "            df_temp1 = vars()['df'+ frame][rows[1][0]].str.split('&',expand=True)\n",
    "            df_temp2 = pd.DataFrame(index=range(df_temp1.shape[0]), columns=range(len(rows[1][1].split(','))))\n",
    "            df_temp2.columns = [rows[1][0] + \".\" + text for text in rows[1][1].split(',')]\n",
    "            Subpar_list = rows[1][1].split(',')\n",
    "            for i in df_temp1.index:\n",
    "                for x in df_temp1.columns:\n",
    "                    try:\n",
    "                        if any(df_temp1[x][i].split('-')[0] in chk for chk in Subpar_list):\n",
    "                            df_temp2[rows[1][0] + \".\" + df_temp1[x][i].split('-')[0]][i]= df_temp1[x][i].split('-')[1]\n",
    "                        else: pass\n",
    "                    except AttributeError:pass\n",
    "        except AttributeError: pass\n",
    "        try:\n",
    "            vars()['df'+ frame] = pd.merge(vars()['df'+ frame],df_temp2, left_index=True, right_index=True)    \n",
    "        except NameError: pass\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117dadfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-16 14:08:11.206727\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------#\n",
    "#                                #\n",
    "#   Saving the MOs to Excel      #\n",
    "#                                #\n",
    "#--------------------------------#\n",
    "\n",
    "# Each MO will be saved in its own sheet\n",
    "\n",
    "#initialze the excel writer\n",
    "writer = pd.ExcelWriter('PCC_SCC_MO.xlsx')\n",
    "\n",
    "#loop thru and put each on a specific sheet (sheetname is the DF Name without the initial df)\n",
    "for frame in sheet_to_include:\n",
    "    vars()['df'+ frame] = pd.merge(vars()['df'+ frame],claro_net_detail, on=['eNodeB Name'])\n",
    "    for col in reversed(colList):\n",
    "        temp = vars()['df'+ frame].pop(col)\n",
    "        vars()['df'+ frame].insert(0, col, temp)\n",
    "    vars()['df'+ frame] = vars()['df'+ frame].copy() # Remove the fragmentation    \n",
    "    vars()['df'+ frame].to_excel(writer, sheet_name = frame, index=False)\n",
    "\n",
    "#close the Excel Writer\n",
    "writer.close()\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200747ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
